Surfel Next Best View
=====================

The `surfel_next_best_view` ROS package evaluates view poses of a pinhole sensor in a surfel cloud.
The main node is `surfel_next_best_view`.

The node operates on a binary surfel cloud, where two kinds of surfels are present.
Known surfels separate empty from known space, while unknown surfels separate unknown from known space.

Given a point cloud and a sequence of sensor poses, the node produces a score for each pose, which represents the amount of unknown surface which is visible from that pose.

The node uses OpenGL hardware acceleration.

Related Publication
-------------------

+ R. Monica and J. Aleotti, "Surfel-Based Next Best View Planning", in IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3324-3331, Oct. 2018

Dependencies
------------

+ ROS (Robot Operating System) (Kinetic)
+ PCL (Point Cloud Library)
+ OpenGL 3.3
+ GLEW
+ Eigen3
+ X11
+ `init_fake_opengl_context`: `https://github.com/RMonica/init_fake_opengl_context`
+ `surfel_next_best_view_render_robot_urdf_plugin`: *optional* dependency to use the robot self filter, from `https://github.com/RMonica/surfel_next_best_view_render_robot_urdf_plugin`

Usage
-----

The `surfel_next_best_view` node creates two actionlib action servers, `~/set_point_cloud` and `~/evaluate_poses`.

The `~/set_point_cloud` action sets the surfel cloud.
The action type is specified in

```surfel_next_best_view_msgs/action/SetPointCloud.action```

The `cloud` field should be filled with a PCL point cloud of type `pcl::PointSurfel`.
The cloud may also be sent to topic `point_cloud`.
These fields of `PointSurfel` are required:

+ **x,y,z**: the point position.
+ **normal_x,normal_y,normal_z**: the normal perpendicular to the surfel.
+ **radius**: the surfel radius.
+ **confidence**: `0` for known surfels, `1` for unknown surfels.
+ **r,g,b**: the surfel color (optional, used only if `with_color` is set - see below).

The point cloud may not be set while view evaluation is in progress.

Once the point cloud is set, an evaluation request may be sent to the action server `~/evaluate_poses`.
Action type is specified in

```surfel_next_best_view_msgs/action/EvaluatePoses.action```

Required fields of `~/evaluate_poses`:

+ **poses**: the view poses to be evaluated
+ **unknown_score**: the importance of visible unknown surface. If you want to explore unknown space, usually you set this to `1`.
+ **occupied_score**: the importance of visible known surface. Normally this is `0`, but some applications (e.g. registration) may require higher values.
+ **distance_weight**: the importance of an (estimated) surface of one unit (e.g. one square meter).
+ **absolute_weight**: the importance of a pixel.
+ **width,height,focal_x,focal_y,center_x,center_y**: sensor intrinsic parameters, in pixels.
+ **range_min,range_max** sensor minimum and maximum range.

Optional fields of `~/evaluate_poses`:

+ **joint_states,robot_pose**: these are used by a robot plugin to add an occluding robot to the scene.
+ **with_images,with_color,with_clouds,enable_lighting**: these change which fields of the response will be populated (see below).
+ **filter_type,filter_data**: only surfels inside this volume contribute to the score. Surfels outside can still provide occlusions.
+ **input_filter_type,input_filter_data**: as above, but surfels outside the volume are ignored (no occlusions).

The node computes a score for each view pose.
Given the amount of known and unknown pixels `kp` and `up` in the simulated view, and the estimated visible area of known and unknown surfels `ks` and `us`:
```
score = kp * known_score * absolute_weight *
        up * unknown_score * absolute_weight *
        ks * known_score * distance_weight *
        us * unknown_score * distance_weight
```

The `~/evaluate_poses` action response contains the following fields:

+ **scores[]**: array of scores, one for each viewpoint.
+ **occupied[]**: `ks * distance_weight + kp * absolute_weight`.
+ **unknown[]**: `us * distance_weight + up * absolute_weight`.
+ **out_of_range[]**: number of out-of-range pixels.
+ **images[]**: if `with_images` was set in the request, grayscale intensity<sup>1</sup> images, or RGBA images (where A is the intensity) if `with_color` was set.
+ **clouds[]**: if `with_clouds`, point clouds generated by the rendering process. Fields are `x`,`y`,`z`,`intensity`<sup>1</sup>, plus  `r`,`g`,`b`,`a` if `with_color` was enabled.
 
<sup>1</sup>Intensity is proportional to the contribution of the pixel to `ks` or `us`, multiplied by -1 for `us`. For images, the range is also rescaled between 0 and 255. Intensity is mostly useful for debugging.

**Note**  
When `with_clouds` or `with_images` is enabled, memory usage grows with the number of evaluated view poses. Use with care.

Parameters
----------

Parameters and default values are listed in `src/surfel_next_best_view_node.h`.

+ **evaluate_poses_action**: name of the `evaluate_poses` action.
+ **set_point_cloud_action**: name of the `set_point_cloud` action.
+ **set_point_cloud_topic**: name of the input `point_cloud` topic.
+ **fake_opengl_context_screen**: X screen to be used (usually `:0`).
+ **frame_id**: TF frame id for published clouds
+ **enable_robot_filter**: whether to enable the robot filter plugin.
+ **robot_filter_plugin**: name of the plugin. By default `RenderRobotURDFPlugin`, from package `surfel_next_best_view_render_robot_urdf_plugin`.










